# HBM(고대역폭메모리) 시장 분석 리포트 2024

## 시장 개요

### HBM이란?
High Bandwidth Memory(HBM)는 여러 개의 DRAM 칩을 수직으로 적층하고
TSV(Through Silicon Via) 기술로 연결한 차세대 고성능 메모리입니다.

### 핵심 스펙 비교

| 구분 | HBM3E | HBM3 | GDDR6 |
|------|-------|------|-------|
| 대역폭 | 1.15TB/s | 819GB/s | 768GB/s |
| 용량 | 36GB | 24GB | 24GB |
| 적층 | 12단 | 8단 | - |
| 전력효율 | 5pJ/bit | 6pJ/bit | 15pJ/bit |

## 시장 규모 및 전망

### 글로벌 HBM 시장
| 연도 | 시장규모 | 성장률 |
|------|---------|--------|
| 2023년 | 40억 달러 | - |
| 2024년 | 160억 달러 | +300% |
| 2025년 | 300억 달러 | +87.5% |
| 2026년 | 400억 달러 | +33.3% |

### 수요처별 비중 (2024년)
- AI 학습용 GPU: 65%
- AI 추론 서버: 20%
- HPC/슈퍼컴퓨터: 10%
- 기타: 5%

## 공급업체 현황

### SK하이닉스
- 시장점유율: 53% (2024년 Q3)
- HBM3E 12단 양산 중
- NVIDIA向 1위 공급사
- 2025년 HBM 매출 전망: 15조원

### 삼성전자
- 시장점유율: 40%
- HBM3E 8단 양산, 12단 개발 중
- 수율 개선으로 NVIDIA 공급 확대 추진
- AMD, Google向 공급 확대

### 마이크론
- 시장점유율: 7%
- HBM3E 8단 양산
- 후발주자로 점유율 확대 중

## 주요 수요처

### NVIDIA
- H100 GPU: HBM3 80GB 탑재
- H200 GPU: HBM3E 141GB 탑재
- B100 GPU: HBM3E 192GB 탑재 예정
- 연간 HBM 수요: 약 100억 달러

### AMD
- MI300X: HBM3 192GB 탑재
- 2024년 AI 가속기 매출 45억 달러 전망

### Google TPU
- TPU v5p: HBM2e 탑재
- 차세대 TPU v6: HBM3 도입 예정

## 기술 동향

### HBM4 (2025년~)
- 대역폭: 1.5TB/s 이상
- 용량: 48GB 이상
- 적층: 16단
- 로직 다이 통합 가능

### 패키징 기술
- CoWoS (TSMC): 업계 표준
- I-Cube4 (삼성): 자체 개발
- 2.5D/3D 패키징 수요 급증

## 공급 부족 현황

### 2024년 상황
- 수요 대비 공급 부족률: 약 20%
- 주요 병목: CoWoS 패키징 Capa
- 리드타임: 6개월 이상

### 증설 계획
- SK하이닉스: 청주 M15X 신규 공장 (2025년)
- 삼성전자: 평택 P4 라인 전환
- TSMC: CoWoS Capa 2배 증설

## 투자 포인트

### 긍정적 요인
1. AI 투자 지속 확대
2. 공급 부족으로 가격 상승
3. 기술 장벽으로 진입 제한

### 리스크 요인
1. 경기 침체 시 AI 투자 축소
2. 중국 자체 개발 가속화
3. 과잉 투자 가능성

## 관련 종목

| 종목 | 티커 | 투자포인트 |
|------|------|-----------|
| SK하이닉스 | 000660.KS | HBM 1위, AI 수혜 |
| 삼성전자 | 005930.KS | 점유율 회복 기대 |
| 한미반도체 | 042700.KQ | HBM 패키징 장비 |
| 이수페타시스 | 007660.KS | HBM PCB 기판 |

---
본 자료는 공개된 정보를 기반으로 작성되었으며, 투자 권유가 아닙니다.
최종 업데이트: 2024년 10월
