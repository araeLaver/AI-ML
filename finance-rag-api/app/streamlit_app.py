# -*- coding: utf-8 -*-
"""
Finance RAG API - í¬íŠ¸í´ë¦¬ì˜¤ ì›¹ ë°ëª¨

[í¬íŠ¸í´ë¦¬ì˜¤ í•µì‹¬]
- í”„ë¡œì íŠ¸ ì†Œê°œ ë° ì•„í‚¤í…ì²˜ ì„¤ëª…
- ìŠ¤íŠ¸ë¦¬ë° RAG Q&A ë°ëª¨
- ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”

ì‹¤í–‰:
    streamlit run app/streamlit_app.py --server.port 8501
"""

import streamlit as st
import requests
import time
import json
import sys
from pathlib import Path
from typing import Optional, Generator

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€ (ë¡œì»¬ ëª¨ë“ˆ importìš©)
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# API ì„œë²„ ì„¤ì •
API_BASE_URL = "http://localhost:8000/api/v1"

# ============================================================
# í˜ì´ì§€ ì„¤ì •
# ============================================================

st.set_page_config(
    page_title="Finance RAG - AI ê¸ˆìœµ Q&A",
    page_icon="ğŸ’°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================
# ì»¤ìŠ¤í…€ CSS
# ============================================================

st.markdown("""
<style>
    /* ë©”ì¸ í—¤ë” */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 2rem;
    }

    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .info-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin-bottom: 1rem;
    }

    /* ì¶œì²˜ ì¹´ë“œ */
    .source-card {
        background: #e8f4f8;
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 0.5rem;
        border-left: 3px solid #17a2b8;
    }

    /* ì‹ ë¢°ë„ ë°°ì§€ */
    .confidence-high { color: #28a745; font-weight: bold; }
    .confidence-medium { color: #ffc107; font-weight: bold; }
    .confidence-low { color: #dc3545; font-weight: bold; }

    /* ì•„í‚¤í…ì²˜ ë°•ìŠ¤ */
    .arch-box {
        background: #1e1e1e;
        color: #d4d4d4;
        padding: 1rem;
        border-radius: 8px;
        font-family: 'Consolas', monospace;
        font-size: 0.85rem;
        overflow-x: auto;
    }

    /* ê¸°ìˆ  ìŠ¤íƒ íƒœê·¸ */
    .tech-tag {
        display: inline-block;
        background: #667eea;
        color: white;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        margin: 0.2rem;
        font-size: 0.85rem;
    }

    /* ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ì»¤ì„œ */
    .streaming-cursor {
        display: inline-block;
        width: 10px;
        height: 20px;
        background: #667eea;
        animation: blink 1s infinite;
    }

    @keyframes blink {
        0%, 50% { opacity: 1; }
        51%, 100% { opacity: 0; }
    }
</style>
""", unsafe_allow_html=True)

# ============================================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================

if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_page" not in st.session_state:
    st.session_state.current_page = "intro"

# ============================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================

def check_api_health() -> bool:
    """API ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=3)
        return response.status_code == 200
    except:
        return False


def get_api_stats() -> Optional[dict]:
    """API í†µê³„ ì¡°íšŒ"""
    try:
        response = requests.get(f"{API_BASE_URL}/stats", timeout=5)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None


def stream_rag_response(question: str, top_k: int = 3) -> Generator:
    """
    RAG ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ - ë¡œì»¬ ëª¨ë“ˆ ì§ì ‘ í˜¸ì¶œ
    """
    try:
        from src.rag.vectorstore import VectorStoreService
        from src.rag.rag_service import RAGService
        from src.core.config import get_settings

        settings = get_settings()
        vectorstore = VectorStoreService(
            persist_dir=settings.chroma_persist_dir,
            collection_name="finance_docs"
        )
        rag_service = RAGService(
            vectorstore=vectorstore,
            llm_model="llama3.2",
            top_k=top_k,
            temperature=0.2
        )

        for chunk in rag_service.query_stream(question):
            yield chunk

    except Exception as e:
        yield {"type": "error", "content": str(e)}


def get_documents(limit: int = 20) -> Optional[dict]:
    """ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get(f"{API_BASE_URL}/documents?limit={limit}", timeout=10)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return None


def upload_document(file, source_name: str, chunk_size: int) -> Optional[dict]:
    """ë¬¸ì„œ ì—…ë¡œë“œ"""
    try:
        files = {"file": (file.name, file, file.type)}
        data = {"source_name": source_name, "chunk_size": str(chunk_size), "chunk_overlap": "100"}
        response = requests.post(f"{API_BASE_URL}/upload", files=files, data=data, timeout=60)
        if response.status_code == 201:
            return response.json()
        else:
            return {"error": True, "detail": response.json().get("detail", "ì—…ë¡œë“œ ì‹¤íŒ¨")}
    except Exception as e:
        return {"error": True, "detail": str(e)}


# ============================================================
# ì‚¬ì´ë“œë°” - ë„¤ë¹„ê²Œì´ì…˜
# ============================================================

with st.sidebar:
    st.image("https://img.icons8.com/fluency/96/money-bag.png", width=80)
    st.title("Finance RAG")
    st.caption("AI ê¸ˆìœµ ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ")

    st.divider()

    # ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´
    st.subheader("ğŸ“‘ ë©”ë‰´")

    menu_options = {
        "intro": "ğŸ  í”„ë¡œì íŠ¸ ì†Œê°œ",
        "demo": "ğŸ’¬ Q&A ë°ëª¨",
        "docs": "ğŸ“„ ë¬¸ì„œ ê´€ë¦¬",
        "tech": "ğŸ”§ ê¸°ìˆ  ìƒì„¸"
    }

    for key, label in menu_options.items():
        if st.button(label, key=f"nav_{key}", use_container_width=True):
            st.session_state.current_page = key
            st.rerun()

    st.divider()

    # API ìƒíƒœ
    st.subheader("âš¡ ì‹œìŠ¤í…œ ìƒíƒœ")
    api_healthy = check_api_health()

    if api_healthy:
        st.success("ğŸŸ¢ API ì„œë²„ ì—°ê²°ë¨")
        stats = get_api_stats()
        if stats:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ë¬¸ì„œ ìˆ˜", stats.get("total_documents", 0))
            with col2:
                st.metric("Top-K", stats.get("top_k", 3))
    else:
        st.error("ğŸ”´ API ì„œë²„ ì˜¤í”„ë¼ì¸")
        st.caption("```\nuvicorn src.main:app --reload\n```")

    st.divider()
    st.caption("Made with â¤ï¸ by ê¹€ë‹¤ìš´")


# ============================================================
# í˜ì´ì§€: í”„ë¡œì íŠ¸ ì†Œê°œ
# ============================================================

def render_intro_page():
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ’° Finance RAG API</h1>
        <p>ê¸ˆìœµ ë¬¸ì„œ ê¸°ë°˜ AI Q&A ì‹œìŠ¤í…œ - LLM í™˜ê° ë°©ì§€ RAG êµ¬í˜„</p>
    </div>
    """, unsafe_allow_html=True)

    # í”„ë¡œì íŠ¸ ê°œìš”
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ¯ ì™œ ë§Œë“¤ì—ˆë‚˜ìš”?")
        st.markdown("""
        <div class="info-card">
        <h4>ë¬¸ì œ ì¸ì‹</h4>
        LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì€ ê°•ë ¥í•˜ì§€ë§Œ <b>í™˜ê°(Hallucination)</b> ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.
        ê¸ˆìœµ ë¶„ì•¼ì—ì„œëŠ” ì˜ëª»ëœ ì •ë³´ê°€ ì‹¤ì œ íˆ¬ì ì†ì‹¤ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆì–´ íŠ¹íˆ ìœ„í—˜í•©ë‹ˆë‹¤.

        <h4>í•´ê²° ë°©ì•ˆ</h4>
        <b>RAG(Retrieval-Augmented Generation)</b>ë¥¼ ì ìš©í•˜ì—¬:
        <ul>
            <li>ê²€ì¦ëœ ê¸ˆìœµ ë¬¸ì„œì—ì„œë§Œ ì •ë³´ë¥¼ ê²€ìƒ‰</li>
            <li>LLMì´ ê²€ìƒ‰ëœ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€</li>
            <li>ë‹µë³€ì˜ ì¶œì²˜ì™€ ì‹ ë¢°ë„ë¥¼ ëª…ì‹œ</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

        st.subheader("ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜")
        st.markdown("""
        <div class="arch-box">
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Finance RAG API                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚   ğŸ‘¤ User                                                            â”‚
â”‚     â”‚                                                                â”‚
â”‚     â–¼                                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚   Streamlit  â”‚â”€â”€â”€â–¶â”‚   FastAPI    â”‚â”€â”€â”€â–¶â”‚  RAG Service â”‚         â”‚
â”‚   â”‚   (Web UI)   â”‚    â”‚   (REST)     â”‚    â”‚  (Pipeline)  â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                   â”‚                  â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                              â”‚                    â”‚            â”‚    â”‚
â”‚                              â–¼                    â–¼            â”‚    â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚    â”‚
â”‚                        â”‚ ChromaDB â”‚        â”‚  Ollama  â”‚       â”‚    â”‚
â”‚                        â”‚ (Vector) â”‚        â”‚  (LLM)   â”‚       â”‚    â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚    â”‚
â”‚                                                                â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š RAG íŒŒì´í”„ë¼ì¸:
1. ì§ˆë¬¸ ì…ë ¥ â†’ 2. ë²¡í„° ê²€ìƒ‰ â†’ 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ 4. LLM ìƒì„± â†’ 5. ì¶œì²˜ì™€ ë°˜í™˜
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.subheader("ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ")

        tech_stack = {
            "Backend": ["FastAPI", "Python 3.11", "Pydantic"],
            "AI/ML": ["Ollama", "LLama 3.2", "ChromaDB"],
            "Testing": ["pytest", "35 tests"],
            "DevOps": ["Docker", "Docker Compose"],
            "Frontend": ["Streamlit"]
        }

        for category, techs in tech_stack.items():
            st.markdown(f"**{category}**")
            tags = " ".join([f'<span class="tech-tag">{t}</span>' for t in techs])
            st.markdown(tags, unsafe_allow_html=True)
            st.write("")

        st.subheader("âœ¨ ì£¼ìš” ê¸°ëŠ¥")
        features = [
            "ğŸ” ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰",
            "ğŸ¤– ìŠ¤íŠ¸ë¦¬ë° LLM ì‘ë‹µ",
            "ğŸ“„ PDF/í…ìŠ¤íŠ¸ íŒŒì‹±",
            "ğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜ ì œê³µ",
            "ğŸ”’ API Key ì¸ì¦",
            "âš¡ Rate Limiting"
        ]
        for f in features:
            st.markdown(f"- {f}")

    st.divider()

    # í•µì‹¬ ì½”ë“œ í•˜ì´ë¼ì´íŠ¸
    st.subheader("ğŸ’¡ í•µì‹¬ êµ¬í˜„ í¬ì¸íŠ¸")

    tab1, tab2, tab3 = st.tabs(["í™˜ê° ë°©ì§€ í”„ë¡¬í”„íŠ¸", "ë²¡í„° ê²€ìƒ‰", "ì²­í‚¹ ì „ëµ"])

    with tab1:
        st.code('''
# í™˜ê° ë°©ì§€ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ ìƒë‹´ AIì…ë‹ˆë‹¤.

ê·œì¹™:
1. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ê°€ ì œê³µëœ ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
2. ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
3. ìˆ«ìë‚˜ ìˆ˜ì¹˜ëŠ” ë¬¸ì„œ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ì„¸ìš”
4. ë‹µë³€ ë§ˆì§€ë§‰ì— ì°¸ì¡° ë¬¸ì„œë¥¼ í‘œì‹œí•˜ì„¸ìš”

ì£¼ì˜:
- ì´ ì •ë³´ëŠ” íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤
- ì‹¤ì œ íˆ¬ì ê²°ì •ì€ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”"""
        ''', language="python")

    with tab2:
        st.code('''
# ChromaDB ë²¡í„° ê²€ìƒ‰
def search(self, query: str, top_k: int = 5):
    results = self.collection.query(
        query_texts=[query],
        n_results=top_k,
        include=["documents", "metadatas", "distances"]
    )

    # ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜
    relevance = 1 - distance / 2  # 0~1 ì •ê·œí™”
    return results
        ''', language="python")

    with tab3:
        st.code('''
# LangChain ìŠ¤íƒ€ì¼ ì¬ê·€ì  í…ìŠ¤íŠ¸ ë¶„í• 
class RecursiveTextSplitter:
    def __init__(self, chunk_size=500, chunk_overlap=100):
        self.separators = ["\\n\\n", "\\n", ". ", " "]

    def split(self, text: str) -> List[str]:
        # ë¬¸ë‹¨ â†’ ë¬¸ì¥ â†’ ë‹¨ì–´ ìˆœìœ¼ë¡œ ë¶„í•  ì‹œë„
        # ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ìµœëŒ€í•œ ìœ ì§€
        ''', language="python")


# ============================================================
# í˜ì´ì§€: Q&A ë°ëª¨
# ============================================================

def render_demo_page():
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ’¬ RAG Q&A ë°ëª¨</h1>
        <p>ê¸ˆìœµ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)</p>
    </div>
    """, unsafe_allow_html=True)

    # ì„¤ì •
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", 1, 10, 3)
    with col2:
        st.write("")  # ìŠ¤í˜ì´ì„œ
    with col3:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.rerun()

    st.divider()

    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # ì¶œì²˜ ì‹œê°í™”
            if message["role"] == "assistant" and "sources" in message and message["sources"]:
                with st.expander("ğŸ“š ì°¸ì¡° ë¬¸ì„œ ë° ê´€ë ¨ë„", expanded=False):
                    for source in message["sources"]:
                        score = source.get("relevance_score", 0)
                        score_pct = int(score * 100)

                        st.markdown(f"""
                        <div class="source-card">
                            <b>{source['source']}</b>
                            <div style="background: #ddd; border-radius: 10px; height: 8px; margin: 5px 0;">
                                <div style="background: linear-gradient(90deg, #667eea, #764ba2);
                                            width: {score_pct}%; height: 100%; border-radius: 10px;"></div>
                            </div>
                            <small>ê´€ë ¨ë„: {score_pct}%</small><br>
                            <small style="color: #666;">{source['content_preview']}</small>
                        </div>
                        """, unsafe_allow_html=True)

    # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼
    if not st.session_state.messages:
        st.markdown("#### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸ì„ í´ë¦­í•´ë³´ì„¸ìš”")
        example_questions = [
            "ETFê°€ ë­”ê°€ìš”?",
            "ë¶„ì‚° íˆ¬ìì˜ ì¥ì ì€?",
            "ì´ˆë³´ì íˆ¬ì ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”",
            "ë ˆë²„ë¦¬ì§€ ETFëŠ” ì™œ ìœ„í—˜í•œê°€ìš”?"
        ]

        cols = st.columns(4)
        for i, q in enumerate(example_questions):
            with cols[i]:
                if st.button(q, key=f"example_{i}"):
                    st.session_state.pending_question = q
                    st.rerun()

    # ì§ˆë¬¸ ì…ë ¥
    if prompt := st.chat_input("ê¸ˆìœµì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”..."):
        process_question(prompt, top_k)

    # ì˜ˆì‹œ ì§ˆë¬¸ ì²˜ë¦¬
    if "pending_question" in st.session_state:
        question = st.session_state.pending_question
        del st.session_state.pending_question
        process_question(question, top_k)


def process_question(question: str, top_k: int):
    """ì§ˆë¬¸ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": question})

    with st.chat_message("user"):
        st.markdown(question)

    # AI ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        sources_placeholder = st.empty()

        full_response = ""
        sources = []
        confidence = "medium"

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
            for chunk in stream_rag_response(question, top_k):
                if chunk["type"] == "sources":
                    sources = chunk["content"]
                    # ê²€ìƒ‰ ì™„ë£Œ í‘œì‹œ
                    sources_placeholder.info(f"ğŸ“š {len(sources)}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
                    time.sleep(0.3)
                    sources_placeholder.empty()

                elif chunk["type"] == "token":
                    full_response += chunk["content"]
                    response_placeholder.markdown(full_response + "â–Œ")

                elif chunk["type"] == "done":
                    confidence = chunk.get("confidence", "medium")

                elif chunk["type"] == "error":
                    st.error(f"ì˜¤ë¥˜: {chunk['content']}")
                    return

        # ìµœì¢… ì‘ë‹µ í‘œì‹œ
        response_placeholder.markdown(full_response)

        # ì‹ ë¢°ë„ í‘œì‹œ
        confidence_emoji = {"high": "ğŸŸ¢", "medium": "ğŸŸ¡", "low": "ğŸ”´"}
        confidence_text = {"high": "ë†’ìŒ", "medium": "ë³´í†µ", "low": "ë‚®ìŒ"}
        st.caption(f"{confidence_emoji.get(confidence, 'âšª')} ì‹ ë¢°ë„: {confidence_text.get(confidence, 'ì•Œ ìˆ˜ ì—†ìŒ')}")

        # ì¶œì²˜ ì‹œê°í™”
        if sources:
            with st.expander("ğŸ“š ì°¸ì¡° ë¬¸ì„œ ë° ê´€ë ¨ë„", expanded=True):
                for source in sources:
                    score = source.get("relevance_score", 0)
                    score_pct = int(score * 100)

                    st.markdown(f"""
                    <div class="source-card">
                        <b>{source['source']}</b>
                        <div style="background: #ddd; border-radius: 10px; height: 8px; margin: 5px 0;">
                            <div style="background: linear-gradient(90deg, #667eea, #764ba2);
                                        width: {score_pct}%; height: 100%; border-radius: 10px;"></div>
                        </div>
                        <small>ê´€ë ¨ë„: {score_pct}%</small><br>
                        <small style="color: #666;">{source['content_preview']}</small>
                    </div>
                    """, unsafe_allow_html=True)

        # ì„¸ì…˜ì— ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": full_response,
            "sources": sources,
            "confidence": confidence
        })


# ============================================================
# í˜ì´ì§€: ë¬¸ì„œ ê´€ë¦¬
# ============================================================

def render_docs_page():
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“„ ë¬¸ì„œ ê´€ë¦¬</h1>
        <p>RAG ì‹œìŠ¤í…œì— ê¸ˆìœµ ë¬¸ì„œë¥¼ ì¶”ê°€í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")

        uploaded_file = st.file_uploader(
            "PDF ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼",
            type=["pdf", "txt", "md"],
            help="ì§€ì› í˜•ì‹: PDF, TXT, Markdown"
        )

        source_name = st.text_input("ì¶œì²˜ëª…", placeholder="ì˜ˆ: íˆ¬ìê°€ì´ë“œ 2024")
        chunk_size = st.slider("ì²­í¬ í¬ê¸°", 200, 1000, 500, help="ë¬¸ì„œë¥¼ ë‚˜ëˆ„ëŠ” ë‹¨ìœ„ (ê¸€ì ìˆ˜)")

        if uploaded_file and st.button("ğŸ“¤ ì—…ë¡œë“œ", type="primary"):
            with st.spinner("ì—…ë¡œë“œ ë° ì²˜ë¦¬ ì¤‘..."):
                result = upload_document(
                    uploaded_file,
                    source_name or uploaded_file.name,
                    chunk_size
                )

            if result and not result.get("error"):
                st.success(f"âœ… {result['chunks_created']}ê°œ ì²­í¬ ìƒì„±!")
                st.balloons()
            else:
                st.error(f"âŒ {result.get('detail', 'ì—…ë¡œë“œ ì‹¤íŒ¨')}")

    with col2:
        st.subheader("ğŸ“‹ ë“±ë¡ëœ ë¬¸ì„œ")

        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
            st.rerun()

        docs = get_documents(50)
        if docs and docs.get("documents"):
            st.metric("ì´ ë¬¸ì„œ ìˆ˜", docs.get("total_count", 0))

            for doc in docs["documents"][:15]:
                meta = doc.get("metadata", {})
                source = meta.get("source", "Unknown")

                with st.expander(f"ğŸ“„ {source}"):
                    st.markdown(f"**ID**: `{doc.get('id', 'N/A')[:30]}...`")
                    st.markdown(f"**ë‚´ìš©**: {doc.get('content_preview', 'ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ')}")
        else:
            st.info("ë“±ë¡ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")


# ============================================================
# í˜ì´ì§€: ê¸°ìˆ  ìƒì„¸
# ============================================================

def render_tech_page():
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ”§ ê¸°ìˆ  ìƒì„¸</h1>
        <p>í”„ë¡œì íŠ¸ì˜ ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­</p>
    </div>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°", "ğŸ”„ RAG íŒŒì´í”„ë¼ì¸", "ğŸ§ª í…ŒìŠ¤íŠ¸", "ğŸ³ ë°°í¬"])

    with tab1:
        st.subheader("í”„ë¡œì íŠ¸ êµ¬ì¡°")
        st.code('''
finance-rag-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # API Layer
â”‚   â”‚   â”œâ”€â”€ routes.py           # REST ì—”ë“œí¬ì¸íŠ¸ (7ê°œ)
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â”œâ”€â”€ security.py         # API Key + Rate Limiting
â”‚   â”‚   â”œâ”€â”€ middleware.py       # ìš”ì²­ ë¡œê¹…
â”‚   â”‚   â””â”€â”€ exception_handlers.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                    # RAG Core
â”‚   â”‚   â”œâ”€â”€ rag_service.py      # RAG íŒŒì´í”„ë¼ì¸ (í•µì‹¬!)
â”‚   â”‚   â”œâ”€â”€ vectorstore.py      # ChromaDB ë˜í¼
â”‚   â”‚   â””â”€â”€ document_loader.py  # PDF/í…ìŠ¤íŠ¸ íŒŒì‹± + ì²­í‚¹
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # ê³µí†µ ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ config.py           # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ logging.py          # êµ¬ì¡°í™”ëœ ë¡œê¹…
â”‚   â”‚   â””â”€â”€ exceptions.py       # ì»¤ìŠ¤í…€ ì˜ˆì™¸ (15ê°œ)
â”‚   â”‚
â”‚   â””â”€â”€ main.py                 # FastAPI ì•± ì§„ì…ì 
â”‚
â”œâ”€â”€ tests/                      # í…ŒìŠ¤íŠ¸ (35ê°œ)
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_vectorstore.py
â”‚   â””â”€â”€ test_document_loader.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # ì›¹ ë°ëª¨ (í˜„ì¬ í˜ì´ì§€)
â”‚
â”œâ”€â”€ Dockerfile                  # ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ
â”œâ”€â”€ docker-compose.yml          # API + Ollama ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â””â”€â”€ Makefile                    # í¸ì˜ ëª…ë ¹ì–´
        ''', language="text")

        st.subheader("ë ˆì´ì–´ë“œ ì•„í‚¤í…ì²˜")
        st.markdown("""
        | Layer | ì—­í•  | Spring ë¹„ìœ  |
        |-------|------|-------------|
        | **API Layer** | HTTP ìš”ì²­/ì‘ë‹µ ì²˜ë¦¬ | `@Controller` |
        | **Service Layer** | ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ | `@Service` |
        | **Repository Layer** | ë°ì´í„° ì•¡ì„¸ìŠ¤ | `@Repository` |
        """)

    with tab2:
        st.subheader("RAG íŒŒì´í”„ë¼ì¸ ìƒì„¸")

        st.markdown("""
        ```
        [ì§ˆë¬¸] "ETFê°€ ë­”ê°€ìš”?"
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. Retrieval (ê²€ìƒ‰)                     â”‚
        â”‚    - ì§ˆë¬¸ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜           â”‚
        â”‚    - ChromaDBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰         â”‚
        â”‚    - top_kê°œ ë¬¸ì„œ + ê±°ë¦¬(ìœ ì‚¬ë„) ë°˜í™˜    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2. Augmentation (ì¦ê°•)                  â”‚
        â”‚    - ê²€ìƒ‰ëœ ë¬¸ì„œë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±         â”‚
        â”‚    - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3. Generation (ìƒì„±)                    â”‚
        â”‚    - Ollama (llama3.2)ë¡œ ë‹µë³€ ìƒì„±      â”‚
        â”‚    - ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í† í° ë‹¨ìœ„ ë°˜í™˜         â”‚
        â”‚    - í™˜ê° ë°©ì§€ í”„ë¡¬í”„íŠ¸ ì ìš©             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        [ì‘ë‹µ] + ì¶œì²˜ + ì‹ ë¢°ë„
        ```
        """)

        st.subheader("ì‹ ë¢°ë„ ê³„ì‚°")
        st.code('''
# í‰ê·  ìœ ì‚¬ë„ ê¸°ë°˜ ì‹ ë¢°ë„ íŒë‹¨
avg_relevance = sum(1 - dist/2 for dist in distances) / len(distances)

if avg_relevance > 0.6:
    confidence = "high"    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ë§¤ìš° ê´€ë ¨
elif avg_relevance > 0.4:
    confidence = "medium"  # ì–´ëŠ ì •ë„ ê´€ë ¨
else:
    confidence = "low"     # ê´€ë ¨ì„± ë‚®ìŒ (ì£¼ì˜ í•„ìš”)
        ''', language="python")

    with tab3:
        st.subheader("í…ŒìŠ¤íŠ¸ í˜„í™©")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ í…ŒìŠ¤íŠ¸", "35ê°œ")
        with col2:
            st.metric("í†µê³¼ìœ¨", "100%")
        with col3:
            st.metric("ì»¤ë²„ë¦¬ì§€", "~85%")

        st.markdown("""
        | í…ŒìŠ¤íŠ¸ íŒŒì¼ | í…ŒìŠ¤íŠ¸ ìˆ˜ | ë²”ìœ„ |
        |------------|----------|------|
        | `test_api.py` | 11ê°œ | ëª¨ë“  REST ì—”ë“œí¬ì¸íŠ¸ |
        | `test_document_loader.py` | 16ê°œ | ì²­í‚¹, PDF íŒŒì‹± |
        | `test_vectorstore.py` | 8ê°œ | ê²€ìƒ‰, í•„í„°ë§ |
        """)

        st.code('''
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
pytest tests/ -v --cov=src --cov-report=html
        ''', language="bash")

    with tab4:
        st.subheader("Docker ë°°í¬")

        st.code('''
# ì „ì²´ ìŠ¤íƒ ì‹¤í–‰ (API + Ollama)
docker-compose up -d

# ì„œë¹„ìŠ¤ í™•ì¸
docker-compose ps

# ë¡œê·¸ í™•ì¸
docker-compose logs -f api
        ''', language="bash")

        st.subheader("Dockerfile (ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ)")
        st.code('''
# Stage 1: Builder
FROM python:3.11-slim as builder
WORKDIR /app
COPY requirements.txt .
RUN pip wheel --no-cache-dir --wheel-dir /app/wheels -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim as runtime
COPY --from=builder /app/wheels /wheels
RUN pip install --no-cache-dir /wheels/*

# ë³´ì•ˆ: non-root user
RUN useradd --uid 1000 appuser
USER appuser

CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0"]
        ''', language="dockerfile")


# ============================================================
# ë©”ì¸ ë¼ìš°íŒ…
# ============================================================

page = st.session_state.current_page

if page == "intro":
    render_intro_page()
elif page == "demo":
    render_demo_page()
elif page == "docs":
    render_docs_page()
elif page == "tech":
    render_tech_page()
else:
    render_intro_page()


# ============================================================
# í‘¸í„°
# ============================================================

st.divider()
st.markdown("""
<div style="text-align: center; color: #888; padding: 1rem;">
    ğŸ’° Finance RAG API | FastAPI + Ollama + ChromaDB + Streamlit<br>
    <small>Â© 2024 ê¹€ë‹¤ìš´ - AI/ML í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸</small>
</div>
""", unsafe_allow_html=True)
