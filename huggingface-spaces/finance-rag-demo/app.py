# -*- coding: utf-8 -*-
"""
Finance RAG Demo - HuggingFace Spaces Version
Real-time Stock Data + RAG Q&A with HuggingFace Inference API
"""

import streamlit as st
import os
import requests
import numpy as np
from datetime import datetime
from dataclasses import dataclass
from typing import Optional, List, Dict, Tuple
import json
import time

# ============================================================
# Page Config
# ============================================================
st.set_page_config(
    page_title="Finance RAG Demo",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ============================================================
# CSS Styles
# ============================================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

:root {
    --black: #0a0a0a;
    --white: #fafafa;
    --gray: #888;
    --accent: #ff4d00;
    --green: #26a69a;
    --red: #ef5350;
}

* { font-family: 'Inter', -apple-system, sans-serif; }
.stApp { background: var(--white); }

header[data-testid="stHeader"] { display: none; }
#MainMenu { visibility: hidden; }
footer { visibility: hidden; }

.main-header {
    text-align: center;
    padding: 2rem 0;
    border-bottom: 1px solid #eee;
}
.main-title {
    font-size: 2.5rem;
    font-weight: 700;
    color: var(--black);
    margin-bottom: 0.5rem;
}
.main-subtitle {
    font-size: 1rem;
    color: var(--gray);
}
.badge {
    display: inline-block;
    background: var(--accent);
    color: white;
    padding: 4px 12px;
    border-radius: 20px;
    font-size: 0.75rem;
    margin-left: 10px;
}
.badge-free {
    background: var(--green);
}

.stock-card {
    background: white;
    border: 1px solid #eee;
    border-radius: 12px;
    padding: 1.5rem;
    margin-bottom: 1rem;
}
.stock-name { font-size: 0.85rem; color: var(--gray); margin-bottom: 0.25rem; }
.stock-price { font-size: 1.75rem; font-weight: 700; color: var(--black); }
.stock-change { font-size: 0.9rem; font-weight: 500; }
.stock-up { color: var(--green); }
.stock-down { color: var(--red); }

.source-card {
    background: #f8f9fa;
    border-left: 3px solid var(--accent);
    padding: 1rem;
    margin: 0.5rem 0;
    border-radius: 0 8px 8px 0;
}
.source-title { font-weight: 600; margin-bottom: 0.5rem; }
.source-score { color: var(--green); font-size: 0.8rem; }

.feature-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 12px;
    padding: 1.5rem;
    text-align: center;
}
.feature-icon { font-size: 2rem; margin-bottom: 0.5rem; }
.feature-title { font-size: 1rem; font-weight: 600; }
.feature-desc { font-size: 0.8rem; opacity: 0.9; }
</style>
""", unsafe_allow_html=True)

# ============================================================
# HuggingFace Inference API
# ============================================================
HF_API_URL = "https://api-inference.huggingface.co/models/"
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
LLM_MODEL = "mistralai/Mistral-7B-Instruct-v0.3"

def get_hf_token():
    """Get HuggingFace token from secrets or environment"""
    # Try secrets first (HuggingFace Spaces)
    try:
        return st.secrets.get("HF_TOKEN", os.environ.get("HF_TOKEN", ""))
    except:
        return os.environ.get("HF_TOKEN", "")

def get_embeddings(texts: List[str], token: str = "") -> List[List[float]]:
    """Get embeddings using HuggingFace Inference API"""
    headers = {"Authorization": f"Bearer {token}"} if token else {}

    response = requests.post(
        HF_API_URL + EMBEDDING_MODEL,
        headers=headers,
        json={"inputs": texts, "options": {"wait_for_model": True}},
        timeout=30
    )

    if response.status_code == 200:
        return response.json()
    else:
        # Fallback: simple TF-IDF like embedding
        return simple_embeddings(texts)

def simple_embeddings(texts: List[str]) -> List[List[float]]:
    """Simple fallback embeddings using character n-grams"""
    def text_to_vec(text: str, dim: int = 384) -> List[float]:
        text = text.lower()
        vec = [0.0] * dim
        for i, char in enumerate(text):
            idx = (ord(char) * (i + 1)) % dim
            vec[idx] += 1.0
        # Normalize
        norm = sum(v * v for v in vec) ** 0.5
        if norm > 0:
            vec = [v / norm for v in vec]
        return vec
    return [text_to_vec(t) for t in texts]

def generate_response(prompt: str, token: str = "", max_tokens: int = 500) -> str:
    """Generate response using HuggingFace Inference API"""
    headers = {"Authorization": f"Bearer {token}"} if token else {}

    # Format for Mistral Instruct
    formatted_prompt = f"<s>[INST] {prompt} [/INST]"

    try:
        response = requests.post(
            HF_API_URL + LLM_MODEL,
            headers=headers,
            json={
                "inputs": formatted_prompt,
                "parameters": {
                    "max_new_tokens": max_tokens,
                    "temperature": 0.7,
                    "do_sample": True,
                    "return_full_text": False
                },
                "options": {"wait_for_model": True}
            },
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                return result[0].get("generated_text", "").strip()

        # If API fails, use template response
        return None
    except Exception as e:
        return None

def cosine_similarity(a: List[float], b: List[float]) -> float:
    """Calculate cosine similarity between two vectors"""
    a_np = np.array(a)
    b_np = np.array(b)
    return float(np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np) + 1e-8))

# ============================================================
# Financial Documents (Knowledge Base)
# ============================================================
FINANCIAL_DOCUMENTS = [
    {
        "id": "doc_1",
        "title": "ì‚¼ì„±ì „ì 2024ë…„ 4ë¶„ê¸° ì‹¤ì ",
        "content": """ì‚¼ì„±ì „ìëŠ” 2024ë…„ 4ë¶„ê¸° ë§¤ì¶œ 79ì¡°ì›, ì˜ì—…ì´ìµ 8.1ì¡°ì›ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
ë°˜ë„ì²´ ë¶€ë¬¸ì€ HBM(ê³ ëŒ€ì—­í­ë©”ëª¨ë¦¬) ìˆ˜ìš” ì¦ê°€ë¡œ ì‹¤ì ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.
HBM3E ì–‘ì‚°ì´ ë³¸ê²©í™”ë˜ë©´ì„œ AI ì„œë²„ ì‹œì¥ ì ìœ ìœ¨ì´ í™•ëŒ€ë˜ê³  ìˆìŠµë‹ˆë‹¤.
2025ë…„ì—ëŠ” HBM4 ê°œë°œì„ ì™„ë£Œí•˜ê³  ì–‘ì‚°ì— ëŒì…í•  ì˜ˆì •ì…ë‹ˆë‹¤.
ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ê°€ê²© ìƒìŠ¹ê³¼ í•¨ê»˜ ìˆ˜ìµì„±ì´ í¬ê²Œ ê°œì„ ë  ì „ë§ì…ë‹ˆë‹¤.""",
        "date": "2024-12-15",
        "source": "ì‚¼ì„±ì „ì IR",
        "category": "ì‹¤ì "
    },
    {
        "id": "doc_2",
        "title": "SKí•˜ì´ë‹‰ìŠ¤ AI ë°˜ë„ì²´ ì „ë§",
        "content": """SKí•˜ì´ë‹‰ìŠ¤ëŠ” AI ë°˜ë„ì²´ ì‹œì¥ì—ì„œ HBM ì ìœ ìœ¨ 1ìœ„ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
NVIDIAì™€ì˜ í˜‘ë ¥ì„ í†µí•´ H100, H200 GPUì— HBM3Eë¥¼ ë…ì  ê³µê¸‰ ì¤‘ì…ë‹ˆë‹¤.
2024ë…„ HBM ë§¤ì¶œì€ ì „ë…„ ëŒ€ë¹„ 300% ì´ìƒ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.
2025ë…„ ì˜ˆìƒ HBM ë§¤ì¶œì€ 20ì¡°ì›ì„ ìƒíšŒí•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.
AI ë°ì´í„°ì„¼í„° íˆ¬ì í™•ëŒ€ë¡œ ê³ ëŒ€ì—­í­ ë©”ëª¨ë¦¬ ìˆ˜ìš”ê°€ í­ë°œì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
        "date": "2024-12-20",
        "source": "SKí•˜ì´ë‹‰ìŠ¤ IR",
        "category": "AIë°˜ë„ì²´"
    },
    {
        "id": "doc_3",
        "title": "í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ì „ë§ 2025",
        "content": """í•œêµ­ì€í–‰ì€ 2024ë…„ 11ì›” ê¸°ì¤€ê¸ˆë¦¬ë¥¼ 3.25%ì—ì„œ 3.0%ë¡œ ì¸í•˜í–ˆìŠµë‹ˆë‹¤.
ë¬¼ê°€ ì•ˆì •ì„¸ê°€ ì§€ì†ë˜ë©´ì„œ ì¶”ê°€ ì¸í•˜ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.
2025ë…„ ìƒë°˜ê¸° ì¤‘ 2.75%ê¹Œì§€ ì¸í•˜ë  ê²ƒìœ¼ë¡œ ì‹œì¥ì€ ì˜ˆìƒí•˜ê³  ìˆìŠµë‹ˆë‹¤.
ê¸ˆë¦¬ ì¸í•˜ëŠ” ë¶€ë™ì‚° ì‹œì¥ íšŒë³µê³¼ ê°€ê³„ ì´ì ë¶€ë‹´ ê²½ê°ì— ë„ì›€ì´ ë  ì „ë§ì…ë‹ˆë‹¤.
ë‹¤ë§Œ í™˜ìœ¨ ë³€ë™ì„±ê³¼ ë¯¸êµ­ ê¸ˆë¦¬ ì •ì±…ì— ë”°ë¼ ì†ë„ ì¡°ì ˆ ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤.""",
        "date": "2024-11-28",
        "source": "í•œêµ­ì€í–‰",
        "category": "ê¸ˆë¦¬"
    },
    {
        "id": "doc_4",
        "title": "ë„¤ì´ë²„ AI ì‚¬ì—… í˜„í™© ë° ì „ëµ",
        "content": """ë„¤ì´ë²„ëŠ” í•˜ì´í¼í´ë¡œë°”Xë¥¼ ê¸°ë°˜ìœ¼ë¡œ B2B AI ì„œë¹„ìŠ¤ë¥¼ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
í´ë¡œë°” ìŠ¤íŠœë””ì˜¤ MAUê°€ 100ë§Œì„ ëŒíŒŒí•˜ë©° êµ­ë‚´ 1ìœ„ AI í”Œë«í¼ìœ¼ë¡œ ìë¦¬ì¡ì•˜ìŠµë‹ˆë‹¤.
ë„¤ì´ë²„í´ë¼ìš°ë“œì˜ AI ë§¤ì¶œ ë¹„ì¤‘ì´ 30%ë¥¼ ë„˜ì–´ì„°ìŠµë‹ˆë‹¤.
2025ë…„ì—ëŠ” ì¼ë³¸, ë™ë‚¨ì•„ ì‹œì¥ìœ¼ë¡œ AI ì„œë¹„ìŠ¤ ì§„ì¶œì„ ë³¸ê²©í™”í•  ê³„íšì…ë‹ˆë‹¤.
ê²€ìƒ‰, ì»¤ë¨¸ìŠ¤, ì½˜í…ì¸  ì „ ì˜ì—­ì— AIë¥¼ ì ìš©í•˜ì—¬ ì‚¬ìš©ì ê²½í—˜ì„ í˜ì‹ í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
        "date": "2024-12-10",
        "source": "ë„¤ì´ë²„ IR",
        "category": "AIì‚¬ì—…"
    },
    {
        "id": "doc_5",
        "title": "ì¹´ì¹´ì˜¤ êµ¬ì¡°ì¡°ì • ë° 2025 ì „ëµ",
        "content": """ì¹´ì¹´ì˜¤ëŠ” ë¹„í•µì‹¬ ì‚¬ì—… ì •ë¦¬ë¥¼ í†µí•´ ìˆ˜ìµì„± ê°œì„ ì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì¹´ì¹´ì˜¤ì—”í„°í…Œì¸ë¨¼íŠ¸ì™€ ì¹´ì¹´ì˜¤ëª¨ë¹Œë¦¬í‹°ì˜ IPOë¥¼ 2025ë…„ ì¶”ì§„í•  ì˜ˆì •ì…ë‹ˆë‹¤.
AI ê¸°ìˆ ì„ í™œìš©í•œ ê´‘ê³  íƒ€ê²ŸíŒ… ê³ ë„í™”ë¡œ ê´‘ê³  ë§¤ì¶œì´ 15% ì¦ê°€í–ˆìŠµë‹ˆë‹¤.
2025ë…„ ì˜ì—…ì´ìµë¥  ëª©í‘œëŠ” 15%ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
ì¹´ì¹´ì˜¤í†¡ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”ì‹œì§€ì™€ ì„ ë¬¼í•˜ê¸° ì„œë¹„ìŠ¤ê°€ í•µì‹¬ ìˆ˜ìµì›ìœ¼ë¡œ ì„±ì¥ ì¤‘ì…ë‹ˆë‹¤.""",
        "date": "2024-12-05",
        "source": "ì¹´ì¹´ì˜¤ IR",
        "category": "ì „ëµ"
    },
    {
        "id": "doc_6",
        "title": "2025ë…„ ê¸€ë¡œë²Œ AI ì‹œì¥ ì „ë§",
        "content": """2025ë…„ ê¸€ë¡œë²Œ AI ì‹œì¥ ê·œëª¨ëŠ” 5,000ì–µ ë‹¬ëŸ¬ë¥¼ ë„˜ì–´ì„¤ ì „ë§ì…ë‹ˆë‹¤.
ìƒì„±í˜• AIê°€ ì‹œì¥ ì„±ì¥ì„ ì£¼ë„í•˜ë©°, ê¸°ì—…ìš© AI ì†”ë£¨ì…˜ ìˆ˜ìš”ê°€ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ì£¼ìš” ì„±ì¥ ë¶„ì•¼ëŠ” AI ë°˜ë„ì²´, í´ë¼ìš°ë“œ AI, ì—”í„°í”„ë¼ì´ì¦ˆ AIì…ë‹ˆë‹¤.
Microsoft, Google, Amazonì´ AI ì¸í”„ë¼ íˆ¬ìë¥¼ ëŒ€í­ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.
í•œêµ­ ê¸°ì—…ë“¤ì€ AI ë°˜ë„ì²´ì™€ AI ì„œë¹„ìŠ¤ ë¶„ì•¼ì—ì„œ ê¸€ë¡œë²Œ ê²½ìŸë ¥ì„ í™•ë³´í•˜ê³  ìˆìŠµë‹ˆë‹¤.""",
        "date": "2024-12-18",
        "source": "ê¸€ë¡œë²Œ ë¦¬ì„œì¹˜",
        "category": "ì‹œì¥ì „ë§"
    },
    {
        "id": "doc_7",
        "title": "í…ŒìŠ¬ë¼ FSD ë° ë¡œë³´íƒì‹œ ì „ë§",
        "content": """í…ŒìŠ¬ë¼ëŠ” 2025ë…„ ì™„ì „ììœ¨ì£¼í–‰(FSD) ìƒìš©í™”ë¥¼ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ë¡œë³´íƒì‹œ ì„œë¹„ìŠ¤ 'Cybercab'ì„ 2025ë…„ í•˜ë°˜ê¸° ì¶œì‹œ ì˜ˆì •ì…ë‹ˆë‹¤.
FSD êµ¬ë… ë§¤ì¶œì´ ë¶„ê¸°ë‹¹ 10ì–µ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí–ˆìŠµë‹ˆë‹¤.
ììœ¨ì£¼í–‰ ë°ì´í„° ì¶•ì ëŸ‰ì´ ê²½ìŸì‚¬ ëŒ€ë¹„ 10ë°° ì´ìƒ ë§ìŠµë‹ˆë‹¤.
AI ê¸°ë°˜ ììœ¨ì£¼í–‰ ê¸°ìˆ ì´ í…ŒìŠ¬ë¼ì˜ í•µì‹¬ ê°€ì¹˜ ë™ë ¥ì´ ë˜ê³  ìˆìŠµë‹ˆë‹¤.""",
        "date": "2024-12-12",
        "source": "í…ŒìŠ¬ë¼ IR",
        "category": "ììœ¨ì£¼í–‰"
    },
    {
        "id": "doc_8",
        "title": "ë¹„íŠ¸ì½”ì¸ ë° ì•”í˜¸í™”í 2025 ì „ë§",
        "content": """ë¹„íŠ¸ì½”ì¸ì´ 2024ë…„ ë§ 10ë§Œ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí•˜ë©° ì‚¬ìƒ ìµœê³ ê°€ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.
ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF ìŠ¹ì¸ ì´í›„ ê¸°ê´€ íˆ¬ìì ìœ ì…ì´ í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.
2025ë…„ì—ëŠ” 15ë§Œ ë‹¬ëŸ¬ê¹Œì§€ ìƒìŠ¹í•  ê²ƒì´ë¼ëŠ” ì „ë§ì´ ìš°ì„¸í•©ë‹ˆë‹¤.
ì´ë”ë¦¬ì›€ ETFë„ ìŠ¹ì¸ë˜ë©´ì„œ ì•”í˜¸í™”í ì‹œì¥ ì „ë°˜ì´ í™œì„±í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤.
ë‹¤ë§Œ ê·œì œ ë¶ˆí™•ì‹¤ì„±ê³¼ ë³€ë™ì„± ë¦¬ìŠ¤í¬ëŠ” ì—¬ì „íˆ ì¡´ì¬í•©ë‹ˆë‹¤.""",
        "date": "2024-12-22",
        "source": "ì•”í˜¸í™”í ë¦¬ì„œì¹˜",
        "category": "ì•”í˜¸í™”í"
    }
]

# ============================================================
# Vector Store (In-Memory)
# ============================================================
@st.cache_resource
def build_vector_store():
    """Build vector store with document embeddings"""
    texts = [f"{doc['title']} {doc['content']}" for doc in FINANCIAL_DOCUMENTS]
    token = get_hf_token()
    embeddings = get_embeddings(texts, token)
    return embeddings

def search_documents(query: str, top_k: int = 3) -> List[Tuple[Dict, float]]:
    """Search documents using vector similarity"""
    # Get query embedding
    token = get_hf_token()
    query_embedding = get_embeddings([query], token)[0]

    # Get document embeddings (cached)
    doc_embeddings = build_vector_store()

    # Calculate similarities
    similarities = []
    for i, doc_emb in enumerate(doc_embeddings):
        sim = cosine_similarity(query_embedding, doc_emb)
        similarities.append((FINANCIAL_DOCUMENTS[i], sim))

    # Sort by similarity
    similarities.sort(key=lambda x: x[1], reverse=True)

    return similarities[:top_k]

# ============================================================
# RAG Pipeline
# ============================================================
def rag_query(question: str) -> Tuple[str, List[Tuple[Dict, float]]]:
    """RAG: Retrieve documents and generate answer"""

    # 1. Retrieve relevant documents
    retrieved = search_documents(question, top_k=3)

    # 2. Build context
    context = "\n\n".join([
        f"[{doc['title']}] ({doc['source']}, {doc['date']})\n{doc['content']}"
        for doc, score in retrieved
    ])

    # 3. Generate answer
    prompt = f"""ë‹¤ìŒ ê¸ˆìœµ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

### ì°¸ê³  ë¬¸ì„œ:
{context}

### ì§ˆë¬¸:
{question}

### ë‹µë³€:
ìœ„ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."""

    token = get_hf_token()
    answer = generate_response(prompt, token)

    # Fallback if API fails
    if not answer:
        answer = generate_template_answer(question, retrieved)

    return answer, retrieved

def generate_template_answer(question: str, retrieved: List[Tuple[Dict, float]]) -> str:
    """Generate template-based answer as fallback"""
    if not retrieved:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    top_doc, score = retrieved[0]

    answer = f"""**{top_doc['title']}**ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.

{top_doc['content']}

---
ğŸ“Š **ê´€ë ¨ë„**: {score:.1%}
ğŸ“… **ë‚ ì§œ**: {top_doc['date']}
ğŸ“Œ **ì¶œì²˜**: {top_doc['source']}"""

    return answer

# ============================================================
# Stock Data
# ============================================================
@dataclass
class StockQuote:
    symbol: str
    name: str
    price: float
    change: float
    change_percent: float
    volume: int

@st.cache_data(ttl=300)  # Cache for 5 minutes
def get_stock_data() -> Dict[str, StockQuote]:
    """Get real-time stock data using yfinance"""
    try:
        import yfinance as yf
        stocks = {
            "ì‚¼ì„±ì „ì": "005930.KS",
            "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS",
            "NAVER": "035420.KS",
            "ì¹´ì¹´ì˜¤": "035720.KS",
        }
        result = {}
        for name, symbol in stocks.items():
            try:
                ticker = yf.Ticker(symbol)
                hist = ticker.history(period="2d")
                if not hist.empty and len(hist) >= 1:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                    change = current - prev
                    change_pct = (change / prev * 100) if prev else 0
                    result[name] = StockQuote(
                        symbol=symbol,
                        name=name,
                        price=round(current, 0),
                        change=round(change, 0),
                        change_percent=round(change_pct, 2),
                        volume=int(hist['Volume'].iloc[-1]) if 'Volume' in hist else 0
                    )
            except Exception as e:
                pass
        if result:
            return result
    except ImportError:
        pass

    # Fallback sample data
    return {
        "ì‚¼ì„±ì „ì": StockQuote("005930.KS", "ì‚¼ì„±ì „ì", 71500, 1200, 1.71, 12500000),
        "SKí•˜ì´ë‹‰ìŠ¤": StockQuote("000660.KS", "SKí•˜ì´ë‹‰ìŠ¤", 178000, 3500, 2.01, 3200000),
        "NAVER": StockQuote("035420.KS", "NAVER", 185000, -2000, -1.07, 580000),
        "ì¹´ì¹´ì˜¤": StockQuote("035720.KS", "ì¹´ì¹´ì˜¤", 42000, -500, -1.18, 2100000),
    }

# ============================================================
# Main App
# ============================================================
def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <div class="main-title">
            Finance RAG Pro
            <span class="badge">AI Powered</span>
            <span class="badge badge-free">Free</span>
        </div>
        <div class="main-subtitle">
            HuggingFace ë¬´ë£Œ ëª¨ë¸ ê¸°ë°˜ ê¸ˆìœµ RAG Q&A ì‹œìŠ¤í…œ
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Features
    st.markdown("<br>", unsafe_allow_html=True)
    cols = st.columns(4)
    features = [
        ("ğŸ”", "ë²¡í„° ê²€ìƒ‰", "ì„ë² ë”© ê¸°ë°˜ ì‹œë§¨í‹± ê²€ìƒ‰"),
        ("ğŸ¤–", "LLM ë‹µë³€", "Mistral-7B ëª¨ë¸ ì‚¬ìš©"),
        ("ğŸ“Š", "ì‹¤ì‹œê°„ ì‹œì„¸", "yfinance ì—°ë™"),
        ("ğŸ’°", "ì™„ì „ ë¬´ë£Œ", "HuggingFace API"),
    ]
    for col, (icon, title, desc) in zip(cols, features):
        with col:
            st.markdown(f"""
            <div class="feature-card">
                <div class="feature-icon">{icon}</div>
                <div class="feature-title">{title}</div>
                <div class="feature-desc">{desc}</div>
            </div>
            """, unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)

    # Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ RAG Q&A", "ğŸ“Š ì‹¤ì‹œê°„ ì‹œì„¸", "ğŸ“š ë¬¸ì„œ ëª©ë¡"])

    # ============ TAB 1: RAG Q&A ============
    with tab1:
        st.markdown("### ğŸ¤– ê¸ˆìœµ AI ì–´ì‹œìŠ¤í„´íŠ¸")
        st.markdown("ê¸ˆìœµ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  AIê°€ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

        # Sample questions
        st.markdown("**ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸:**")
        sample_qs = [
            "ì‚¼ì„±ì „ì 4ë¶„ê¸° ì‹¤ì ì€?",
            "HBM ì‹œì¥ ì „ë§ì€?",
            "2025ë…„ ê¸ˆë¦¬ ì „ë§",
            "ë„¤ì´ë²„ AI ì‚¬ì—… í˜„í™©",
        ]

        cols = st.columns(4)
        selected_q = None
        for col, q in zip(cols, sample_qs):
            if col.button(q, use_container_width=True):
                selected_q = q

        # Query input
        query = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=selected_q if selected_q else "",
            placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ì‹¤ì ì€ ì–´ë–¤ê°€ìš”?"
        )

        if query:
            with st.spinner("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                start_time = time.time()
                answer, retrieved = rag_query(query)
                elapsed = time.time() - start_time

            # Answer
            st.markdown("---")
            st.markdown("### ğŸ“ AI ë‹µë³€")
            st.markdown(answer)
            st.caption(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed:.2f}ì´ˆ")

            # Sources
            st.markdown("### ğŸ“š ì°¸ì¡° ë¬¸ì„œ")
            for doc, score in retrieved:
                with st.expander(f"ğŸ“„ {doc['title']} (ê´€ë ¨ë„: {score:.1%})"):
                    st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {doc['category']}")
                    st.markdown(doc['content'])
                    st.caption(f"ì¶œì²˜: {doc['source']} | ë‚ ì§œ: {doc['date']}")

    # ============ TAB 2: Stock Data ============
    with tab2:
        st.markdown("### ğŸ“ˆ ì‹¤ì‹œê°„ ì£¼ìš” ì¢…ëª©")

        stocks = get_stock_data()
        cols = st.columns(2)

        for i, (name, stock) in enumerate(stocks.items()):
            with cols[i % 2]:
                change_class = "stock-up" if stock.change >= 0 else "stock-down"
                change_sign = "+" if stock.change >= 0 else ""

                st.markdown(f"""
                <div class="stock-card">
                    <div class="stock-name">{stock.symbol}</div>
                    <div class="stock-price">{name}</div>
                    <div class="stock-price">â‚©{stock.price:,.0f}</div>
                    <div class="stock-change {change_class}">
                        {change_sign}{stock.change:,.0f} ({change_sign}{stock.change_percent}%)
                    </div>
                    <div style="color: #888; font-size: 0.8rem;">
                        ê±°ë˜ëŸ‰: {stock.volume:,}
                    </div>
                </div>
                """, unsafe_allow_html=True)

        st.caption("* ë°ì´í„°: yfinance | 5ë¶„ë§ˆë‹¤ ê°±ì‹ ")

    # ============ TAB 3: Documents ============
    with tab3:
        st.markdown("### ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤")
        st.markdown(f"ì´ **{len(FINANCIAL_DOCUMENTS)}ê°œ** ë¬¸ì„œê°€ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        # Category filter
        categories = list(set(doc['category'] for doc in FINANCIAL_DOCUMENTS))
        selected_cat = st.selectbox("ì¹´í…Œê³ ë¦¬ í•„í„°", ["ì „ì²´"] + categories)

        for doc in FINANCIAL_DOCUMENTS:
            if selected_cat != "ì „ì²´" and doc['category'] != selected_cat:
                continue
            with st.expander(f"ğŸ“„ {doc['title']} [{doc['category']}]"):
                st.markdown(doc['content'])
                st.caption(f"ì¶œì²˜: {doc['source']} | ë‚ ì§œ: {doc['date']} | ID: {doc['id']}")

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #888; font-size: 0.8rem; padding: 1rem;">
        <p><strong>ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ</strong>: Streamlit + HuggingFace Inference API + yfinance</p>
        <p><strong>ğŸ¤– ëª¨ë¸</strong>: Mistral-7B (LLM) + all-MiniLM-L6-v2 (Embeddings)</p>
        <p>Made with â¤ï¸ by <a href="https://github.com/araeLaver" target="_blank">Kim Dawoon</a> |
        <a href="https://github.com/araeLaver/AI-ML" target="_blank">Full Project on GitHub</a></p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
