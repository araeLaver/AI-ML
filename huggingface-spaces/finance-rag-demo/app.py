# -*- coding: utf-8 -*-
"""
Finance RAG Pro - Production-Grade RAG System
HuggingFace Spaces Version

Features:
- Hybrid Search (Vector + BM25 + RRF)
- Groq API LLM (Fast Response)
- Document Upload (PDF/TXT)
- Re-ranking (Keyword-based)
- 50+ DART-style Sample Documents
"""

import streamlit as st
import time
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

# Config & Modules
from config import get_config, get_secret
from rag.llm_provider import get_llm_provider, BaseLLMProvider
from rag.hybrid_search import HybridSearcher, SearchResult
from rag.reranker import KeywordReranker, RankedDocument
from data.sample_docs import get_all_documents, get_categories, get_document_count
from data.document_loader import DocumentLoader, ChunkingConfig

# ============================================================
# Page Config
# ============================================================
st.set_page_config(
    page_title="Finance RAG Pro",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================
# CSS Styles
# ============================================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

:root {
    --black: #0a0a0a;
    --white: #fafafa;
    --gray: #888;
    --accent: #ff4d00;
    --green: #26a69a;
    --red: #ef5350;
    --blue: #2196f3;
}

* { font-family: 'Inter', -apple-system, sans-serif; }
.stApp { background: var(--white); }

header[data-testid="stHeader"] { display: none; }
#MainMenu { visibility: hidden; }
footer { visibility: hidden; }

.main-header {
    text-align: center;
    padding: 1.5rem 0;
    border-bottom: 1px solid #eee;
    margin-bottom: 1rem;
}
.main-title {
    font-size: 2rem;
    font-weight: 700;
    color: var(--black);
    margin-bottom: 0.25rem;
}
.main-subtitle {
    font-size: 0.9rem;
    color: var(--gray);
}
.badge {
    display: inline-block;
    background: var(--accent);
    color: white;
    padding: 3px 10px;
    border-radius: 15px;
    font-size: 0.7rem;
    margin-left: 8px;
    vertical-align: middle;
}
.badge-groq { background: #f97316; }
.badge-hybrid { background: #8b5cf6; }

.stock-card {
    background: white;
    border: 1px solid #eee;
    border-radius: 12px;
    padding: 1.25rem;
    margin-bottom: 0.75rem;
}
.stock-name { font-size: 0.8rem; color: var(--gray); margin-bottom: 0.2rem; }
.stock-price { font-size: 1.5rem; font-weight: 700; color: var(--black); }
.stock-change { font-size: 0.85rem; font-weight: 500; }
.stock-up { color: var(--green); }
.stock-down { color: var(--red); }

.source-card {
    background: #f8f9fa;
    border-left: 3px solid var(--accent);
    padding: 0.75rem;
    margin: 0.5rem 0;
    border-radius: 0 8px 8px 0;
}

.search-type-badge {
    display: inline-block;
    padding: 2px 8px;
    border-radius: 10px;
    font-size: 0.7rem;
    font-weight: 500;
}
.search-hybrid { background: #ede9fe; color: #7c3aed; }
.search-vector { background: #dbeafe; color: #2563eb; }
.search-keyword { background: #fef3c7; color: #d97706; }

.stat-box {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    border-radius: 10px;
    padding: 1rem;
    text-align: center;
}
.stat-number { font-size: 1.5rem; font-weight: 700; }
.stat-label { font-size: 0.75rem; opacity: 0.9; }
</style>
""", unsafe_allow_html=True)

# ============================================================
# Session State Initialization
# ============================================================
def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if "searcher" not in st.session_state:
        config = get_config()
        st.session_state.searcher = HybridSearcher(
            hf_token=config.hf_token or "",
            vector_weight=config.vector_weight,
            keyword_weight=config.keyword_weight
        )
        # ìƒ˜í”Œ ë¬¸ì„œ ë¡œë“œ
        load_sample_documents()

    if "uploaded_docs" not in st.session_state:
        st.session_state.uploaded_docs = []

    if "reranker" not in st.session_state:
        st.session_state.reranker = KeywordReranker()


def load_sample_documents():
    """ìƒ˜í”Œ ë¬¸ì„œë¥¼ ê²€ìƒ‰ ì—”ì§„ì— ë¡œë“œ"""
    docs = get_all_documents()
    documents = [f"{d['title']}\n{d['content']}" for d in docs]
    doc_ids = [d['id'] for d in docs]
    metadatas = [
        {
            "title": d.get("title", ""),
            "date": d.get("date", ""),
            "source": d.get("source", ""),
            "category": d.get("category", ""),
            "company": d.get("company", ""),
        }
        for d in docs
    ]
    st.session_state.searcher.index_documents(documents, doc_ids, metadatas)


def get_llm() -> Optional[BaseLLMProvider]:
    """LLM Provider ê°€ì ¸ì˜¤ê¸°"""
    config = get_config()
    try:
        return get_llm_provider(
            groq_api_key=config.groq_api_key,
            hf_token=config.hf_token,
            model=config.llm_model,
            temperature=config.llm_temperature
        )
    except Exception as e:
        return None


# ============================================================
# RAG Pipeline
# ============================================================
def rag_query(
    question: str,
    search_mode: str = "hybrid",
    use_rerank: bool = True,
    top_k: int = 5
) -> Tuple[str, List[Dict[str, Any]], float]:
    """
    RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Returns:
        answer, retrieved_docs, elapsed_time
    """
    start_time = time.time()

    # 1. ê²€ìƒ‰
    searcher = st.session_state.searcher
    search_results = searcher.search(question, top_k=top_k * 2, search_mode=search_mode)

    # 2. Re-ranking (ì„ íƒ)
    if use_rerank and search_results:
        reranker = st.session_state.reranker
        docs_for_rerank = [
            {
                "doc_id": r.doc_id,
                "content": r.content,
                "score": r.score,
                "metadata": r.metadata,
                "search_type": r.search_type
            }
            for r in search_results
        ]
        reranked = reranker.rerank(question, docs_for_rerank, top_k=top_k)
        retrieved = [
            {
                "doc_id": r.doc_id,
                "content": r.content,
                "score": r.rerank_score,
                "metadata": r.metadata,
                "search_type": docs_for_rerank[r.original_rank - 1]["search_type"] if r.original_rank <= len(docs_for_rerank) else "unknown"
            }
            for r in reranked
        ]
    else:
        retrieved = [
            {
                "doc_id": r.doc_id,
                "content": r.content,
                "score": r.score,
                "metadata": r.metadata,
                "search_type": r.search_type
            }
            for r in search_results[:top_k]
        ]

    # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_parts = []
    for doc in retrieved:
        meta = doc.get("metadata", {})
        title = meta.get("title", "")
        source = meta.get("source", "")
        date = meta.get("date", "")
        content = doc.get("content", "")

        if title:
            context_parts.append(f"[{title}] ({source}, {date})\n{content}")
        else:
            context_parts.append(content)

    context = "\n\n---\n\n".join(context_parts)

    # 4. LLM ë‹µë³€ ìƒì„±
    llm = get_llm()

    if llm:
        system_prompt = """ë‹¹ì‹ ì€ ê¸ˆìœµ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        user_prompt = f"""### ì°¸ê³  ë¬¸ì„œ:
{context}

### ì§ˆë¬¸:
{question}

### ë‹µë³€:"""

        try:
            response = llm.generate(system_prompt, user_prompt, max_tokens=1024)
            answer = response.content
        except Exception as e:
            answer = generate_fallback_answer(question, retrieved)
    else:
        answer = generate_fallback_answer(question, retrieved)

    elapsed = time.time() - start_time

    return answer, retrieved, elapsed


def generate_fallback_answer(question: str, retrieved: List[Dict[str, Any]]) -> str:
    """API ì‹¤íŒ¨ ì‹œ Fallback ë‹µë³€"""
    if not retrieved:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    top_doc = retrieved[0]
    meta = top_doc.get("metadata", {})
    title = meta.get("title", "ê´€ë ¨ ë¬¸ì„œ")
    content = top_doc.get("content", "")
    score = top_doc.get("score", 0)

    return f"""**{title}**ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.

{content[:500]}{"..." if len(content) > 500 else ""}

---
ğŸ“Š ê´€ë ¨ë„: {score:.1%} | ğŸ“… ë‚ ì§œ: {meta.get('date', 'N/A')} | ğŸ“Œ ì¶œì²˜: {meta.get('source', 'N/A')}

ğŸ’¡ ë” ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ GROQ_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."""


# ============================================================
# Stock Data
# ============================================================
@dataclass
class StockQuote:
    symbol: str
    name: str
    price: float
    change: float
    change_percent: float
    volume: int


@st.cache_data(ttl=300)
def get_stock_data() -> Dict[str, StockQuote]:
    """ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„° (yfinance)"""
    try:
        import yfinance as yf
        stocks = {
            "ì‚¼ì„±ì „ì": "005930.KS",
            "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS",
            "NAVER": "035420.KS",
            "ì¹´ì¹´ì˜¤": "035720.KS",
        }
        result = {}
        for name, symbol in stocks.items():
            try:
                ticker = yf.Ticker(symbol)
                hist = ticker.history(period="2d")
                if not hist.empty and len(hist) >= 1:
                    current = hist['Close'].iloc[-1]
                    prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                    change = current - prev
                    change_pct = (change / prev * 100) if prev else 0
                    result[name] = StockQuote(
                        symbol=symbol,
                        name=name,
                        price=round(current, 0),
                        change=round(change, 0),
                        change_percent=round(change_pct, 2),
                        volume=int(hist['Volume'].iloc[-1]) if 'Volume' in hist else 0
                    )
            except Exception:
                pass
        if result:
            return result
    except ImportError:
        pass

    # Fallback
    return {
        "ì‚¼ì„±ì „ì": StockQuote("005930.KS", "ì‚¼ì„±ì „ì", 71500, 1200, 1.71, 12500000),
        "SKí•˜ì´ë‹‰ìŠ¤": StockQuote("000660.KS", "SKí•˜ì´ë‹‰ìŠ¤", 178000, 3500, 2.01, 3200000),
        "NAVER": StockQuote("035420.KS", "NAVER", 185000, -2000, -1.07, 580000),
        "ì¹´ì¹´ì˜¤": StockQuote("035720.KS", "ì¹´ì¹´ì˜¤", 42000, -500, -1.18, 2100000),
    }


# ============================================================
# Sidebar
# ============================================================
def render_sidebar():
    """ì‚¬ì´ë“œë°” ë Œë”ë§"""
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")

        # API ìƒíƒœ í‘œì‹œ
        config = get_config()
        if config.groq_api_key:
            st.success("âœ… Groq API ì—°ê²°ë¨")
        else:
            st.warning("âš ï¸ Groq API ë¯¸ì„¤ì • (Fallback ëª¨ë“œ)")
            st.caption("Secretsì— GROQ_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”")

        st.markdown("---")

        # ê²€ìƒ‰ ì„¤ì •
        st.markdown("### ğŸ” ê²€ìƒ‰ ì„¤ì •")

        search_mode = st.selectbox(
            "ê²€ìƒ‰ ëª¨ë“œ",
            options=["hybrid", "vector", "keyword"],
            format_func=lambda x: {
                "hybrid": "ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ (ì¶”ì²œ)",
                "vector": "ğŸ¯ ë²¡í„° ê²€ìƒ‰",
                "keyword": "ğŸ“ í‚¤ì›Œë“œ ê²€ìƒ‰"
            }[x]
        )

        use_rerank = st.checkbox("Re-ranking ì‚¬ìš©", value=True)
        top_k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 3, 10, 5)

        st.markdown("---")

        # ë¬¸ì„œ ì—…ë¡œë“œ
        st.markdown("### ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "PDF/TXT íŒŒì¼ ì—…ë¡œë“œ",
            type=["pdf", "txt", "md"],
            help="ì—…ë¡œë“œëœ ë¬¸ì„œëŠ” RAG ê²€ìƒ‰ì— ì¶”ê°€ë©ë‹ˆë‹¤"
        )

        if uploaded_file:
            if st.button("ë¬¸ì„œ ì¶”ê°€", type="primary"):
                with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
                    try:
                        loader = DocumentLoader(ChunkingConfig(chunk_size=500, chunk_overlap=100))
                        docs = loader.load_from_uploaded_file(uploaded_file)

                        # ê²€ìƒ‰ ì—”ì§„ì— ì¶”ê°€
                        documents = [d.content for d in docs]
                        doc_ids = [d.id for d in docs]
                        metadatas = [d.metadata for d in docs]

                        st.session_state.searcher.index_documents(documents, doc_ids, metadatas)
                        st.session_state.uploaded_docs.append({
                            "filename": uploaded_file.name,
                            "chunks": len(docs)
                        })
                        st.success(f"âœ… {len(docs)}ê°œ ì²­í¬ ì¶”ê°€ë¨")
                    except Exception as e:
                        st.error(f"âŒ ì˜¤ë¥˜: {e}")

        # ì—…ë¡œë“œëœ ë¬¸ì„œ ëª©ë¡
        if st.session_state.uploaded_docs:
            st.markdown("**ì—…ë¡œë“œëœ ë¬¸ì„œ:**")
            for doc in st.session_state.uploaded_docs:
                st.caption(f"ğŸ“„ {doc['filename']} ({doc['chunks']} chunks)")

        st.markdown("---")

        # í†µê³„
        st.markdown("### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
        stats = st.session_state.searcher.get_stats()
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats["total_documents"])
        st.caption(f"Vector: {stats['vector_store']['model'].split('/')[-1]}")
        st.caption(f"BM25: {stats['bm25']['vocab_size']} ì–´íœ˜")

    return search_mode, use_rerank, top_k


# ============================================================
# Main App
# ============================================================
def main():
    # ì´ˆê¸°í™”
    init_session_state()

    # Header
    st.markdown("""
    <div class="main-header">
        <div class="main-title">
            Finance RAG Pro
            <span class="badge badge-groq">Groq</span>
            <span class="badge badge-hybrid">Hybrid</span>
        </div>
        <div class="main-subtitle">
            Production-Grade RAG | í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Groq LLM
        </div>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar
    search_mode, use_rerank, top_k = render_sidebar()

    # Stats Row
    col1, col2, col3, col4 = st.columns(4)

    config = get_config()
    with col1:
        st.markdown(f"""
        <div class="stat-box">
            <div class="stat-number">{get_document_count()}+</div>
            <div class="stat-label">ìƒ˜í”Œ ë¬¸ì„œ</div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="stat-box">
            <div class="stat-number">Vector+BM25</div>
            <div class="stat-label">í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰</div>
        </div>
        """, unsafe_allow_html=True)

    with col3:
        llm_name = "Groq" if config.groq_api_key else "Fallback"
        st.markdown(f"""
        <div class="stat-box">
            <div class="stat-number">{llm_name}</div>
            <div class="stat-label">LLM Provider</div>
        </div>
        """, unsafe_allow_html=True)

    with col4:
        st.markdown("""
        <div class="stat-box">
            <div class="stat-number">2-3ì´ˆ</div>
            <div class="stat-label">ì˜ˆìƒ ì‘ë‹µì‹œê°„</div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)

    # Tabs
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ RAG Q&A", "ğŸ“Š ì‹¤ì‹œê°„ ì‹œì„¸", "ğŸ“š ë¬¸ì„œ ëª©ë¡"])

    # ============ TAB 1: RAG Q&A ============
    with tab1:
        st.markdown("### ğŸ¤– ê¸ˆìœµ AI ì–´ì‹œìŠ¤í„´íŠ¸")

        # Sample Questions
        st.markdown("**ğŸ“ ì˜ˆì‹œ ì§ˆë¬¸:**")
        sample_qs = [
            "ì‚¼ì„±ì „ì 4ë¶„ê¸° ì‹¤ì ì€?",
            "HBM ì‹œì¥ ì „ë§ì€?",
            "2025ë…„ ê¸ˆë¦¬ ì „ë§",
            "ë„¤ì´ë²„ AI ì‚¬ì—… í˜„í™©",
            "ë¹„íŠ¸ì½”ì¸ ì „ë§",
        ]

        cols = st.columns(5)
        selected_q = None
        for col, q in zip(cols, sample_qs):
            if col.button(q, use_container_width=True, key=f"sample_{q}"):
                selected_q = q

        # Query Input
        query = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            value=selected_q if selected_q else "",
            placeholder="ì˜ˆ: ì‚¼ì„±ì „ì HBM ì „ëµì€?"
        )

        if query:
            with st.spinner("ğŸ” ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                answer, retrieved, elapsed = rag_query(
                    query,
                    search_mode=search_mode,
                    use_rerank=use_rerank,
                    top_k=top_k
                )

            # Answer
            st.markdown("---")
            st.markdown("### ğŸ“ AI ë‹µë³€")
            st.markdown(answer)

            # Metrics
            col1, col2, col3 = st.columns(3)
            col1.metric("ì‘ë‹µ ì‹œê°„", f"{elapsed:.2f}ì´ˆ")
            col2.metric("ê²€ìƒ‰ ëª¨ë“œ", search_mode.upper())
            col3.metric("ê²€ìƒ‰ ê²°ê³¼", f"{len(retrieved)}ê°œ")

            # Sources
            st.markdown("### ğŸ“š ì°¸ì¡° ë¬¸ì„œ")
            for i, doc in enumerate(retrieved):
                meta = doc.get("metadata", {})
                title = meta.get("title", f"ë¬¸ì„œ {i+1}")
                score = doc.get("score", 0)
                search_type = doc.get("search_type", "unknown")

                # Search type badge
                badge_class = {
                    "hybrid": "search-hybrid",
                    "vector": "search-vector",
                    "keyword": "search-keyword"
                }.get(search_type, "search-keyword")

                with st.expander(f"ğŸ“„ {title} (ê´€ë ¨ë„: {score:.1%})"):
                    st.markdown(f"""
                    <span class="search-type-badge {badge_class}">{search_type.upper()}</span>
                    """, unsafe_allow_html=True)
                    st.markdown(f"**ì¹´í…Œê³ ë¦¬**: {meta.get('category', 'N/A')}")
                    st.markdown(f"**ê¸°ì—…**: {meta.get('company', 'N/A')}")
                    st.markdown(doc.get("content", "")[:500] + "...")
                    st.caption(f"ì¶œì²˜: {meta.get('source', 'N/A')} | ë‚ ì§œ: {meta.get('date', 'N/A')}")

    # ============ TAB 2: Stock Data ============
    with tab2:
        st.markdown("### ğŸ“ˆ ì‹¤ì‹œê°„ ì£¼ìš” ì¢…ëª©")

        stocks = get_stock_data()
        cols = st.columns(2)

        for i, (name, stock) in enumerate(stocks.items()):
            with cols[i % 2]:
                change_class = "stock-up" if stock.change >= 0 else "stock-down"
                change_sign = "+" if stock.change >= 0 else ""

                st.markdown(f"""
                <div class="stock-card">
                    <div class="stock-name">{stock.symbol}</div>
                    <div class="stock-price">{name}</div>
                    <div class="stock-price">â‚©{stock.price:,.0f}</div>
                    <div class="stock-change {change_class}">
                        {change_sign}{stock.change:,.0f} ({change_sign}{stock.change_percent}%)
                    </div>
                    <div style="color: #888; font-size: 0.8rem;">
                        ê±°ë˜ëŸ‰: {stock.volume:,}
                    </div>
                </div>
                """, unsafe_allow_html=True)

        st.caption("* ë°ì´í„°: yfinance | 5ë¶„ë§ˆë‹¤ ê°±ì‹ ")

    # ============ TAB 3: Documents ============
    with tab3:
        st.markdown("### ğŸ“š RAG ì§€ì‹ë² ì´ìŠ¤")

        docs = get_all_documents()
        st.markdown(f"ì´ **{len(docs)}ê°œ** ë¬¸ì„œê°€ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

        # Category filter
        categories = ["ì „ì²´"] + sorted(get_categories())
        selected_cat = st.selectbox("ì¹´í…Œê³ ë¦¬ í•„í„°", categories)

        # Document list
        for doc in docs:
            if selected_cat != "ì „ì²´" and doc.get("category") != selected_cat:
                continue

            with st.expander(f"ğŸ“„ {doc['title']} [{doc.get('category', '')}]"):
                st.markdown(doc.get("content", ""))
                st.caption(f"ì¶œì²˜: {doc.get('source', '')} | ë‚ ì§œ: {doc.get('date', '')} | ê¸°ì—…: {doc.get('company', '')}")

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #888; font-size: 0.8rem; padding: 1rem;">
        <p><strong>ğŸ› ï¸ Tech Stack</strong>: Streamlit + Groq API + Hybrid Search (Vector + BM25 + RRF)</p>
        <p><strong>ğŸ¤– Models</strong>: Llama 3.1 (LLM) + all-MiniLM-L6-v2 (Embeddings)</p>
        <p>Made with â¤ï¸ by <a href="https://github.com/araeLaver" target="_blank">Kim Dawoon</a> |
        <a href="https://github.com/araeLaver/AI-ML" target="_blank">Full Project on GitHub</a></p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
