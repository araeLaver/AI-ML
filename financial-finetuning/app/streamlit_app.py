# Streamlit Demo UI
"""
Financial LLM Fine-tuning Demo
"""

import streamlit as st
import requests
import json
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data import FINANCIAL_INSTRUCTIONS, FinancialInstructionDataset

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Financial LLM Fine-tuning",
    page_icon="ğŸ’°",
    layout="wide",
    initial_sidebar_state="expanded",
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 1rem;
    }
    .metric-value {
        font-size: 2rem;
        font-weight: bold;
    }
    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
    }
    .instruction-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin-bottom: 1rem;
    }
    .category-badge {
        background: #e3f2fd;
        color: #1565c0;
        padding: 0.2rem 0.6rem;
        border-radius: 15px;
        font-size: 0.8rem;
        font-weight: 500;
    }
    .output-box {
        background: #f0f7f0;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4caf50;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #f0f2f6;
        border-radius: 4px 4px 0px 0px;
        padding: 10px 20px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1f77b4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)


def main():
    # í—¤ë”
    st.markdown('<p class="main-header">ğŸ’° Financial LLM Fine-tuning</p>', unsafe_allow_html=True)
    st.markdown(
        '<p class="sub-header">ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™” LLM íŒŒì¸íŠœë‹ ë°ëª¨ - LoRA/QLoRA ê¸°ë°˜</p>',
        unsafe_allow_html=True
    )

    # íƒ­ êµ¬ì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š ë°ì´í„°ì…‹",
        "ğŸ¯ í•™ìŠµ ì„¤ì •",
        "ğŸ¤– ì¶”ë¡  í…ŒìŠ¤íŠ¸",
        "ğŸ“ˆ í•™ìŠµ ëª¨ë‹ˆí„°ë§"
    ])

    # íƒ­ 1: ë°ì´í„°ì…‹
    with tab1:
        render_dataset_tab()

    # íƒ­ 2: í•™ìŠµ ì„¤ì •
    with tab2:
        render_training_config_tab()

    # íƒ­ 3: ì¶”ë¡  í…ŒìŠ¤íŠ¸
    with tab3:
        render_inference_tab()

    # íƒ­ 4: í•™ìŠµ ëª¨ë‹ˆí„°ë§
    with tab4:
        render_monitoring_tab()


def render_dataset_tab():
    """ë°ì´í„°ì…‹ íƒ­ ë Œë”ë§"""
    st.subheader("ğŸ“Š ê¸ˆìœµ ë„ë©”ì¸ í•™ìŠµ ë°ì´í„°ì…‹")

    # ë°ì´í„°ì…‹ í†µê³„
    try:
        dataset = FinancialInstructionDataset()
        stats = dataset.get_statistics()

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ì „ì²´ ìƒ˜í”Œ", stats["total_samples"])
        with col2:
            st.metric("í•™ìŠµ ìƒ˜í”Œ", stats["train_samples"])
        with col3:
            st.metric("í‰ê°€ ìƒ˜í”Œ", stats["eval_samples"])
        with col4:
            st.metric("í‰ê·  ê¸¸ì´", f"{stats['avg_text_length']:.0f}ì")

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        st.subheader("ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬")
        categories = stats["categories"]

        # ì°¨íŠ¸ ë°ì´í„°
        import pandas as pd
        df_cat = pd.DataFrame([
            {"ì¹´í…Œê³ ë¦¬": k, "ìƒ˜í”Œ ìˆ˜": v}
            for k, v in categories.items()
        ])
        st.bar_chart(df_cat.set_index("ì¹´í…Œê³ ë¦¬"))

    except Exception as e:
        st.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        st.info("datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
    st.subheader("ìƒ˜í”Œ ë°ì´í„°")

    # ì¹´í…Œê³ ë¦¬ í•„í„°
    all_categories = list(set(item.get("category", "general") for item in FINANCIAL_INSTRUCTIONS))
    selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", ["ì „ì²´"] + all_categories)

    # í•„í„°ë§ëœ ë°ì´í„°
    filtered_data = FINANCIAL_INSTRUCTIONS
    if selected_category != "ì „ì²´":
        filtered_data = [
            item for item in FINANCIAL_INSTRUCTIONS
            if item.get("category") == selected_category
        ]

    # ë°ì´í„° í‘œì‹œ
    for i, item in enumerate(filtered_data[:5]):  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
        with st.expander(f"ìƒ˜í”Œ {i+1}: {item['instruction'][:50]}...", expanded=(i == 0)):
            st.markdown(f"""
            <div class="instruction-card">
                <span class="category-badge">{item.get('category', 'general')}</span>
                <h4>ì§€ì‹œì‚¬í•­</h4>
                <p>{item['instruction']}</p>
            </div>
            """, unsafe_allow_html=True)

            if item.get("input"):
                st.markdown("**ì…ë ¥:**")
                st.code(item["input"], language=None)

            st.markdown("**ì‘ë‹µ:**")
            st.markdown(f"""
            <div class="output-box">
                {item['output'][:500]}{'...' if len(item['output']) > 500 else ''}
            </div>
            """, unsafe_allow_html=True)


def render_training_config_tab():
    """í•™ìŠµ ì„¤ì • íƒ­ ë Œë”ë§"""
    st.subheader("ğŸ¯ LoRA/QLoRA í•™ìŠµ ì„¤ì •")

    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    config_path = project_root / "configs" / "training_config.yaml"

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ëª¨ë¸ ì„¤ì •")

        model_name = st.selectbox(
            "ë² ì´ìŠ¤ ëª¨ë¸",
            [
                "beomi/Llama-3-Open-Ko-8B",
                "beomi/llama-2-ko-7b",
                "Qwen/Qwen2.5-7B-Instruct",
                "mistralai/Mistral-7B-Instruct-v0.2",
            ],
            index=0,
        )

        max_seq_length = st.slider("ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´", 512, 4096, 2048, 256)

        st.markdown("### LoRA ì„¤ì •")
        lora_r = st.slider("LoRA Rank (r)", 4, 64, 16, 4)
        lora_alpha = st.slider("LoRA Alpha", 8, 128, 32, 8)
        lora_dropout = st.slider("LoRA Dropout", 0.0, 0.2, 0.05, 0.01)

    with col2:
        st.markdown("### ì–‘ìí™” ì„¤ì •")

        use_quantization = st.checkbox("QLoRA ì‚¬ìš© (4-bit)", value=True)

        if use_quantization:
            quant_type = st.selectbox("ì–‘ìí™” íƒ€ì…", ["nf4", "fp4"], index=0)
            use_double_quant = st.checkbox("Double Quantization", value=True)

        st.markdown("### í•™ìŠµ ì„¤ì •")
        num_epochs = st.slider("ì—í¬í¬ ìˆ˜", 1, 10, 3)
        batch_size = st.slider("ë°°ì¹˜ í¬ê¸°", 1, 16, 4)
        learning_rate = st.select_slider(
            "í•™ìŠµë¥ ",
            options=[1e-5, 2e-5, 5e-5, 1e-4, 2e-4, 5e-4, 1e-3],
            value=2e-4,
            format_func=lambda x: f"{x:.0e}",
        )
        gradient_accumulation = st.slider("Gradient Accumulation", 1, 16, 4)

    # ì„¤ì • ìš”ì•½
    st.markdown("---")
    st.subheader("ğŸ“‹ ì„¤ì • ìš”ì•½")

    effective_batch = batch_size * gradient_accumulation
    st.info(f"ì‹¤íš¨ ë°°ì¹˜ í¬ê¸°: {effective_batch} (batch_size Ã— gradient_accumulation)")

    # ì„¤ì • JSON í‘œì‹œ
    config_dict = {
        "model": {
            "name": model_name,
            "max_seq_length": max_seq_length,
        },
        "lora": {
            "r": lora_r,
            "lora_alpha": lora_alpha,
            "lora_dropout": lora_dropout,
        },
        "quantization": {
            "enabled": use_quantization,
            "load_in_4bit": use_quantization,
        },
        "training": {
            "num_train_epochs": num_epochs,
            "per_device_train_batch_size": batch_size,
            "learning_rate": learning_rate,
            "gradient_accumulation_steps": gradient_accumulation,
        },
    }

    with st.expander("ì„¤ì • JSON ë³´ê¸°"):
        st.json(config_dict)

    # í•™ìŠµ ì‹œì‘ ë²„íŠ¼
    st.markdown("---")
    col1, col2, col3 = st.columns([2, 1, 2])

    with col2:
        if st.button("ğŸš€ í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
            st.warning("ì‹¤ì œ í•™ìŠµì€ GPUê°€ í•„ìš”í•©ë‹ˆë‹¤. CLIì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”:")
            st.code("python -m src.training.train_lora --config configs/training_config.yaml")


def render_inference_tab():
    """ì¶”ë¡  í…ŒìŠ¤íŠ¸ íƒ­ ë Œë”ë§"""
    st.subheader("ğŸ¤– ì¶”ë¡  í…ŒìŠ¤íŠ¸")

    # API ì„œë²„ ìƒíƒœ í™•ì¸
    api_url = st.text_input("API ì„œë²„ URL", value="http://localhost:8000")

    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button("ì„œë²„ ìƒíƒœ í™•ì¸"):
            try:
                response = requests.get(f"{api_url}/health", timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    if data.get("model_loaded"):
                        st.success("âœ… ëª¨ë¸ ë¡œë“œë¨")
                    else:
                        st.warning("âš ï¸ ëª¨ë¸ ë¯¸ë¡œë“œ")
                else:
                    st.error("âŒ ì„œë²„ ì˜¤ë¥˜")
            except requests.exceptions.ConnectionError:
                st.error("âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    st.markdown("---")

    # ì¶”ë¡  ìœ í˜• ì„ íƒ
    inference_type = st.radio(
        "ì¶”ë¡  ìœ í˜•",
        ["ì¼ë°˜ ì§ˆì˜", "ì´ìƒê±°ë˜ íƒì§€", "íˆ¬ì ë¶„ì„", "ìƒí’ˆ ì„¤ëª…"],
        horizontal=True,
    )

    # ì…ë ¥ ì˜ì—­
    if inference_type == "ì¼ë°˜ ì§ˆì˜":
        instruction = st.text_area(
            "ì§€ì‹œì‚¬í•­",
            value="ê¸ˆë¦¬ ì¸ìƒì´ ì£¼ì‹ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            height=100,
        )
        input_text = st.text_area("ì…ë ¥ (ì„ íƒ)", value="", height=100)

    elif inference_type == "ì´ìƒê±°ë˜ íƒì§€":
        instruction = "ë‹¤ìŒ ê¸ˆìœµ ê±°ë˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì´ìƒ ê±°ë˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•´ì£¼ì„¸ìš”."
        st.text_area("ì§€ì‹œì‚¬í•­ (ê³ ì •)", value=instruction, height=80, disabled=True)
        input_text = st.text_area(
            "ê±°ë˜ ì •ë³´",
            value="ê³„ì¢Œë²ˆí˜¸: 123-456-789\nê±°ë˜ê¸ˆì•¡: 5ì–µì›\nê±°ë˜ì‹œê°„: ìƒˆë²½ 3ì‹œ 15ë¶„\nê±°ë˜ ìœ í˜•: í•´ì™¸ ì†¡ê¸ˆ\nìˆ˜ì·¨ì¸: í•´ì™¸ ë²•ì¸",
            height=150,
        )

    elif inference_type == "íˆ¬ì ë¶„ì„":
        instruction = "ê¸ˆìœµ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."
        st.text_area("ì§€ì‹œì‚¬í•­ (ê³ ì •)", value=instruction, height=80, disabled=True)
        input_text = st.text_area(
            "íˆ¬ì ì§ˆë¬¸",
            value="í˜„ì¬ ê¸ˆë¦¬ ì¸ìƒ ê¸°ì¡°ì—ì„œ ì±„ê¶Œ íˆ¬ì ì „ëµì€ ì–´ë–»ê²Œ ì„¸ì›Œì•¼ í• ê¹Œìš”?",
            height=100,
        )

    else:  # ìƒí’ˆ ì„¤ëª…
        instruction = "ë‹¤ìŒ ê¸ˆìœµ ìƒí’ˆì— ëŒ€í•´ ì¼ë°˜ ê³ ê°ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        st.text_area("ì§€ì‹œì‚¬í•­ (ê³ ì •)", value=instruction, height=80, disabled=True)
        input_text = st.text_area(
            "ìƒí’ˆ ì •ë³´",
            value="ìƒí’ˆëª…: KBêµ­ë¯¼ ì ë¦½ì‹ í€ë“œ\nìœ í˜•: ì£¼ì‹í˜¼í•©í˜•\níˆ¬ìê¸°ê°„: 3ë…„\nëª©í‘œìˆ˜ìµë¥ : ì—° 7%",
            height=150,
        )

    # ìƒì„± íŒŒë¼ë¯¸í„°
    with st.expander("ìƒì„± íŒŒë¼ë¯¸í„°"):
        col1, col2, col3 = st.columns(3)
        with col1:
            temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1)
            top_p = st.slider("Top P", 0.0, 1.0, 0.9, 0.05)
        with col2:
            top_k = st.slider("Top K", 1, 100, 50)
            max_tokens = st.slider("Max Tokens", 64, 2048, 512, 64)
        with col3:
            repetition_penalty = st.slider("Repetition Penalty", 1.0, 2.0, 1.1, 0.1)

    # ìƒì„± ë²„íŠ¼
    if st.button("ğŸ¯ ì‘ë‹µ ìƒì„±", type="primary"):
        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
            try:
                response = requests.post(
                    f"{api_url}/generate",
                    json={
                        "instruction": instruction,
                        "input_text": input_text,
                        "temperature": temperature,
                        "top_p": top_p,
                        "top_k": top_k,
                        "max_new_tokens": max_tokens,
                        "repetition_penalty": repetition_penalty,
                    },
                    timeout=120,
                )

                if response.status_code == 200:
                    data = response.json()
                    st.markdown("### ğŸ“ ìƒì„±ëœ ì‘ë‹µ")
                    st.markdown(f"""
                    <div class="output-box">
                        {data['response']}
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.error(f"API ì˜¤ë¥˜: {response.status_code}")

            except requests.exceptions.ConnectionError:
                st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                st.code("python api/server.py")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë°ëª¨ ì‘ë‹µ (API ì—†ì´)
    st.markdown("---")
    st.subheader("ğŸ“Œ ìƒ˜í”Œ ì‘ë‹µ (ë°ëª¨)")

    demo_responses = {
        "ì¼ë°˜ ì§ˆì˜": """ê¸ˆë¦¬ ì¸ìƒì€ ì£¼ì‹ ì‹œì¥ì— ë‹¤ì–‘í•œ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤:

1. **ë¶€ì •ì  ì˜í–¥**
   - ê¸°ì—… ì°¨ì…ë¹„ìš© ì¦ê°€ë¡œ ìˆ˜ìµì„± ì•…í™”
   - í• ì¸ìœ¨ ìƒìŠ¹ìœ¼ë¡œ ì£¼ì‹ ê°€ì¹˜ í•˜ë½
   - ì±„ê¶Œ ë“± ëŒ€ì²´ íˆ¬ìì²˜ë¡œ ìê¸ˆ ì´ë™

2. **ì„¹í„°ë³„ ì°¨ë³„í™”**
   - ê¸ˆìœµì£¼: ìˆœì´ìë§ˆì§„ ê°œì„ ìœ¼ë¡œ ê¸ì •ì 
   - ì„±ì¥ì£¼: ë¯¸ë˜ í˜„ê¸ˆíë¦„ í• ì¸ì— ë¯¼ê°í•˜ì—¬ ë¶€ì •ì 
   - ë°°ë‹¹ì£¼: ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì 

3. **íˆ¬ì ì „ëµ**
   - ê°€ì¹˜ì£¼ ì¤‘ì‹¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
   - í˜„ê¸ˆ íë¦„ì´ ì•ˆì •ì ì¸ ê¸°ì—… ì„ í˜¸
   - ë¶„ì‚° íˆ¬ìë¡œ ë¦¬ìŠ¤í¬ ê´€ë¦¬""",

        "ì´ìƒê±°ë˜ íƒì§€": """**ìœ„í—˜ ìˆ˜ì¤€: ë†’ìŒ (High Risk)**

**ì´ìƒ ì§•í›„ ë¶„ì„:**
1. ê±°ë˜ ì‹œê°„ ì´ìƒ: ìƒˆë²½ 3ì‹œ 15ë¶„ì€ ì¼ë°˜ì ì¸ ê¸ˆìœµ ê±°ë˜ ì‹œê°„ëŒ€ê°€ ì•„ë‹˜
2. ëŒ€ê·œëª¨ ê±°ë˜: 5ì–µì›ì€ ê³ ì•¡ ê±°ë˜ë¡œ ì¶”ê°€ ê²€ì¦ í•„ìš”
3. í•´ì™¸ ì†¡ê¸ˆ: ìê¸ˆì„¸íƒ ìœ„í—˜ì´ ìˆëŠ” ê±°ë˜ ìœ í˜•
4. ìˆ˜ì·¨ì¸ í™•ì¸: í•´ì™¸ ë²•ì¸ì˜ ì‹¤ì²´ í™•ì¸ í•„ìš”

**ê¶Œì¥ ì¡°ì¹˜:**
- ê±°ë˜ ë³´ë¥˜ ë° ê³ ê° ì‹ ì› ì¬í™•ì¸
- ìê¸ˆì¶œì²˜ ì¦ë¹™ ìš”ì²­
- ì˜ì‹¬ê±°ë˜ë³´ê³ (STR) ê²€í† 
- AML ë‹´ë‹¹ë¶€ì„œ ì—ìŠ¤ì»¬ë ˆì´ì…˜""",
    }

    demo_key = inference_type if inference_type in demo_responses else "ì¼ë°˜ ì§ˆì˜"
    st.markdown(f"""
    <div class="output-box">
        {demo_responses[demo_key]}
    </div>
    """, unsafe_allow_html=True)


def render_monitoring_tab():
    """í•™ìŠµ ëª¨ë‹ˆí„°ë§ íƒ­ ë Œë”ë§"""
    st.subheader("ğŸ“ˆ í•™ìŠµ ëª¨ë‹ˆí„°ë§")

    st.info("ì‹¤ì œ í•™ìŠµ ì§„í–‰ ì‹œ TensorBoard ë˜ëŠ” Weights & Biasesì—ì„œ ìƒì„¸ ëª¨ë‹ˆí„°ë§ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    # ëª¨ì˜ í•™ìŠµ ë©”íŠ¸ë¦­
    st.markdown("### í•™ìŠµ ì§„í–‰ ìƒí™© (ìƒ˜í”Œ)")

    import pandas as pd
    import numpy as np

    # ëª¨ì˜ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    epochs = list(range(1, 11))
    train_loss = [2.5 * np.exp(-0.3 * e) + 0.2 + np.random.normal(0, 0.05) for e in epochs]
    eval_loss = [2.7 * np.exp(-0.25 * e) + 0.25 + np.random.normal(0, 0.08) for e in epochs]

    df_metrics = pd.DataFrame({
        "Epoch": epochs,
        "Train Loss": train_loss,
        "Eval Loss": eval_loss,
    })

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### Loss ê³¡ì„ ")
        st.line_chart(df_metrics.set_index("Epoch")[["Train Loss", "Eval Loss"]])

    with col2:
        st.markdown("#### í•™ìŠµ ìƒíƒœ")
        progress = 0.7  # 70% ì™„ë£Œ
        st.progress(progress)
        st.write(f"ì§„í–‰ë¥ : {progress * 100:.0f}%")

        st.metric("í˜„ì¬ ì—í¬í¬", "7 / 10")
        st.metric("í˜„ì¬ Loss", f"{train_loss[6]:.4f}")
        st.metric("Best Eval Loss", f"{min(eval_loss[:7]):.4f}")

    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    st.markdown("### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ (ìƒ˜í”Œ)")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("GPU ë©”ëª¨ë¦¬", "12.5 GB / 24 GB")
        st.progress(0.52)
    with col2:
        st.metric("GPU ì‚¬ìš©ë¥ ", "85%")
        st.progress(0.85)
    with col3:
        st.metric("í•™ìŠµ ì†ë„", "2.3 it/s")

    # TensorBoard ì—°ë™
    st.markdown("---")
    st.markdown("### TensorBoard ì—°ë™")
    st.code("""
# TensorBoard ì‹¤í–‰
tensorboard --logdir outputs/runs

# ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
# http://localhost:6006
    """)


if __name__ == "__main__":
    main()
